{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f74983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7868b842",
   "metadata": {},
   "source": [
    "Set some parameters for Shi-Thomasi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a11e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Shi-Tomasi corner detection (good features to track paper)\n",
    "corner_track_params = dict(maxCorners = 10,\n",
    "                           qualityLevel = 0.3,\n",
    "                           minDistance = 7,\n",
    "                           blockSize = 7 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e258a971",
   "metadata": {},
   "source": [
    "goodFeaturesToTrack(image, maxCorners, qualityLevel, minDistance[, corners[, mask[, blockSize[, useHarrisDetector[, k]]]]]) -> corners\n",
    ".   @brief Determines strong corners on an image.\n",
    ".   \n",
    ".   The function finds the most prominent corners in the image or in the specified image region, as\n",
    ".   described in @cite Shi94\n",
    ".   \n",
    ".   -   Function calculates the corner quality measure at every source image pixel using the\n",
    ".       #cornerMinEigenVal or #cornerHarris .\n",
    ".   -   Function performs a non-maximum suppression (the local maximums in *3 x 3* neighborhood are\n",
    ".       retained).\n",
    ".   -   The corners with the minimal eigenvalue less than\n",
    ".       \\f$\\texttt{qualityLevel} \\cdot \\max_{x,y} qualityMeasureMap(x,y)\\f$ are rejected.\n",
    ".   -   The remaining corners are sorted by the quality measure in the descending order.\n",
    ".   -   Function throws away each corner for which there is a stronger corner at a distance less than\n",
    ".       maxDistance.\n",
    ".   \n",
    ".   The function can be used to initialize a point-based tracker of an object.\n",
    ".   \n",
    ".   @note If the function is called with different values A and B of the parameter qualityLevel , and\n",
    ".   A \\> B, the vector of returned corners with qualityLevel=A will be the prefix of the output vector\n",
    ".   with qualityLevel=B .\n",
    ".   \n",
    ".   @param image Input 8-bit or floating-point 32-bit, single-channel image.\n",
    ".   @param corners Output vector of detected corners.\n",
    ".   @param maxCorners Maximum number of corners to return. If there are more corners than are found,\n",
    ".   the strongest of them is returned. `maxCorners <= 0` implies that no limit on the maximum is set\n",
    ".   and all detected corners are returned.\n",
    ".   @param qualityLevel Parameter characterizing the minimal accepted quality of image corners. The\n",
    ".   parameter value is multiplied by the best corner quality measure, which is the minimal eigenvalue\n",
    ".   (see #cornerMinEigenVal ) or the Harris function response (see #cornerHarris ). The corners with the\n",
    ".   quality measure less than the product are rejected. For example, if the best corner has the\n",
    ".   quality measure = 1500, and the qualityLevel=0.01 , then all the corners with the quality measure\n",
    ".   less than 15 are rejected.\n",
    ".   @param minDistance Minimum possible Euclidean distance between the returned corners.\n",
    ".   @param mask Optional region of interest. If the image is not empty (it needs to have the type\n",
    ".   CV_8UC1 and the same size as image ), it specifies the region in which the corners are detected.\n",
    ".   @param blockSize Size of an average block for computing a derivative covariation matrix over each\n",
    ".   pixel neighborhood. See cornerEigenValsAndVecs ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "732673ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lk_params = dict(winSize= (200,200) , maxLevel= 2 , criteria=(cv2.TERM_CRITERIA_COUNT | cv2.TERM_CRITERIA_EPS ,10, 0.03))\n",
    "#- Window size (200,200) smaller size --> more sensitive to noise but can not catch large optical motion \n",
    "\n",
    "#- maxlevel --> lucase-kanade use pyramid levels to subsample the image or frame  --> =2 == 1/4 resolution\n",
    "#    https://en.wikipedia.org/wiki/Pyramid_%28image_processing%29\n",
    "\n",
    "# criteria has two here - the max number (10 above) of iterations and epsilon (0.03 above).\n",
    "#- More iterations means a more exhaustive search for the points in current frame Vs prev. frame(How many iterations will take looking for these points)\n",
    "#- and a smaller epsilon means that we will finish earlier. \n",
    "#- These are primarily useful in exchanging speed vs accuracy, but mainly stay the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f09f6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret , prev_frame = cap.read()\n",
    "\n",
    "prev_gray= cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# the points we want to track \n",
    "\n",
    "#Grab using corner_tracking_parameters some goodfeaturetotrack \n",
    "\n",
    "# Grab top 10 corners and track those\n",
    "\n",
    "prevPts= cv2.goodFeaturesToTrack(prev_gray, mask=None, **corner_track_params)\n",
    "\n",
    "mask = np.zeros_like(prev_frame)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret , frame = cap.read()\n",
    "\n",
    "    frame_gray= cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    nextPts , status , err = cv2.calcOpticalFlowPyrLK(frame_gray, prev_gray, prevPts , None , **lk_params)\n",
    "    \n",
    "    good_new= nextPts[status==1]\n",
    "    \n",
    "    good_prev= prevPts[status==1]\n",
    "    \n",
    "     # Use ravel to get points to draw lines and circles\n",
    "    for i,(new,prev) in enumerate(zip(good_new,good_prev)):\n",
    "        \n",
    "        x_new,y_new =new.ravel() \n",
    "        x_prev,y_prev = prev.ravel()\n",
    "        \n",
    "        # Lines will be drawn using the mask created from the first frame\n",
    "        mask = cv2.line(mask, pt1=(int(x_new),int(y_new)),pt2=(int(x_prev),int(y_prev)),color=(0,255,0),thickness= 3)\n",
    "        \n",
    "        # Draw red circles at corner points\n",
    "        frame = cv2.circle(frame,(int(x_new),int(y_new)),8,(0,0,255),-1)\n",
    "    \n",
    "    # Display the image along with the mask we drew the line on.\n",
    "    img = cv2.add(frame,mask)\n",
    "    cv2.imshow('frame',img)\n",
    "    \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "   \n",
    "    # Now update the previous frame and previous points\n",
    "    prev_gray = frame_gray.copy()\n",
    "    prevPts = good_new.reshape(-1,1,2)\n",
    "    \n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc8e9b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[363.86227, 264.00778]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de18eba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[363.83908, 264.21875]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f698b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363.86227 264.00778\n"
     ]
    }
   ],
   "source": [
    "    for i,(new,prev) in enumerate(zip(good_new,good_prev)):\n",
    "        \n",
    "        x_new,y_new = new.ravel()\n",
    "        x_prev,y_prev = prev.ravel()\n",
    "        print (x_new, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60784e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=type(x_new)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcc848e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
